Q.1 As a security consultant, you have been working on a prototype of the
    attack target; before the product is deployed, the vendor is willing to
    make any alteration necessary (in software or hardware) to prevent the
    attack. Explain the options available, and which one you would
    recommend.

    Assuming we only alter the underlying software or hardware and not the protocol of 
    decryption we have 2 options available to us:
    1) Masking: i.e applying a reversible transformation to the intermediate values
    in the calculations. Ideally this means that the actual processing is performed with
    randomised values and thus the power traces will be independent of the actual values
    from the calculation. As this is a software based alteration, this does not require
    any changes to the hardware specifications of the device.

    2) Hiding: i.e making the power consumption appear to be random or constant.
    An indirect method of altering the power consumption is to hide the time dimension
    of the execution which has the effect of making the power consumption trace appear
    randomised. Two software solutions one can employ are randomly performing 
    dummy operations (NOP instructions or instructions with random data) and 
    shuffling (changing the sequence of the S-box look-ups at random).
    A second method which directly impacts the power consumption is to hide the 
    amplitude dimension by lowering the SNR. This can be achieved by either 
    reducing the signal such that an equal amount of power is used to perform all operations
    and for all data values essentially giving us a set of power traces which appears constant
    (this can be achieved by performing independent operations in parallel)
    or by increasing the noise which would, simillarly to the masking countermeasure,
    make the power consumption appear random(this can be done by filtering the power net).

    My recomendation would be to use masking as well as hiding the time dimension as these
    would be both software alterations and would be simpler to perform than manipulation
    of the SNR which would likely require some hardware changes as well which, in general,
    are more costly.



Q.2 The vendor of the attack target opts to replace the 8-bit Intel 8051
    micro-processor with a modern, 32-bit ARM Cortex-M0; they supplement it
    with hardware support for that allows single-cycle operations on 32
    bits of the AES state.  Doing so will naturally reduce the latency of
    encryption or decryption, but they *also* want to know if it might make
    the device more secure wrt.  DPA attacks: what is your assessment, and
    why ?

    By changing to a 32-bit instruction architecture we will require a much
    larger amount of traces in order for the attack to be successfull. The problem
    is that by having 32-bit single-cycle operations we will have to default 
    to guessing blocks of 32-bits of the key every time. This will make it much harder
    since the likelihood that 2 given hypotheses for a 32 bit block guess will produce a similar
    trace given our model (in this case I assumed it is the Hamming weight) is much higher than before
    which means that we will require significantly more traces in order to obtain a correct guess.
    That being said, the performance of the attack is entirely dependent on the model for the 
    consumption so it is possible that models better than the Hamming weight could be found in this case.
    In conclusion, I believe the device will be more secure vs a power attack with a 32-bit processor than 
    with an 8-bit processor, however it is entirely possible that a well-resourced attacker could still perform 
    a 32-bit DPA attack if he manages to acquire a large amount of power traces.



Q.3 DPA attacks work because statistics can (to some degree) remove the
    noise within power consumption traces.  Explain the concepts of signal,
    noise and signal-to-noise ratio, and the role each has in a DPA attack
    of this type.

    The power consumption of a point has 4 components:
        P_total = P_op + P_data + P_el.noise + P_const
    The signal is described in terms of P_op and P_data and represents the part of the power consumption that is usable by an attacker.
    The noise is described by P_el.noise and is independent of the signal and not exploitable by an attacker.
    Finally, we have P_const which represents the constant components of P_op, P_data and P_el.noise. 
    If we denote the part of P_op and P_data that is actually exploited as P_exp and the remaining part
    as P_sw.noise we can also define P_total as: P_total = P_exp + P_sw.noise + P_el.noise + P_const
    Thus we can define the SNR (signal-to-noise ratio) as: SNR = Var(P_exp) / Var(P_noise)
    i.e. the ratio of the variance of the used part of the signal to the variance of the total noise 
    part of the power trace (including the unused signal denoted as P_sw.noise).
    From this final definition of SNR we observe that the SNR is a quadratic relationship between the signal
    and the noise and that the SNR is directly proportional with the signal and inverse proportional with the noise,
    meaning when we increase the noise our SNR becomes smaller. Ideally, for a DPA attack to succeed, 
    we want the SNR to be high and, therefore, the noise to be low.



Q.4 DPA attacks include a statistical analysis step, for which one option
    is use of the t-test.  Explain what the difference between a standard
    t-test and Kocher's method is.  Given that in a DPA attack one might
    have unequal sets of measurements associated with 0 and 1, is a
    standard t-test actually an appropriate choice?

    While Kocher's method uses the product moment correlation coefficient and the covariance between the simulated 
    and real power traces, the standard t-test uses the difference of means between the two sets of traces.
    Assuming that in the attack we still compute the distinguisher for 8 bits at the time, given that the probability
    of a bit being 1 is 1/2, the mean of the Hamming weights for our power model is likely to be 4.
    Thus, our model is likely to produce the same estimate for the many byte values and will 
    therefore make the t-test likely to evaluate to the same value for many different guesses
    which denies us the ability to make an informed decision for each byte of the key.
    This clearly makes the t-test an inappropriate choice for the task since we need a statistical
    test which produces strong distinguishing values in order to create a clear hypotheses for the
    key in the attack.
